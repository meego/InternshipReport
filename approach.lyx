#LyX 2.0 created this file. For more info see http://www.lyx.org/
\lyxformat 413
\begin_document
\begin_header
\textclass scrartcl
\begin_preamble
\usepackage{graphicx}
\usepackage{listings}
\usepackage{color}
\usepackage{xcolor}
\usepackage{caption}
\usepackage{url}

  \usepackage{courier}
  \lstset{
  	basicstyle=\scriptsize\ttfamily, % Standardschrift
  	%numbers=left,               % Ort der Zeilennummern
  	numberstyle=\tiny,          % Stil der Zeilennummern
  	%stepnumber=2,               % Abstand zwischen den Zeilennummern
  	numbersep=5pt,              % Abstand der Nummern zum Text
  	tabsize=2,                  % Groesse von Tabs
  	extendedchars=true,         %
  	breaklines=true,            % Zeilen werden Umgebrochen
  	keywordstyle=\color{red},
  	frame=b,         
  	%        keywordstyle=[1]\textbf,    % Stil der Keywords
  	%        keywordstyle=[2]\textbf,    %
  	%        keywordstyle=[3]\textbf,    %
  	%        keywordstyle=[4]\textbf,   \sqrt{\sqrt{}} %
  	stringstyle=\color{blue}\ttfamily, % Farbe der String
  	showspaces=false,           % Leerzeichen anzeigen ?
  	showtabs=false,             % Tabs anzeigen ?
  	xleftmargin=17pt,
  	framexleftmargin=17pt,
  	framexrightmargin=5pt,
  	framexbottommargin=4pt,
  	%backgroundcolor=\color{lightgray},
  	showstringspaces=false      % Leerzeichen in Strings anzeigen ?        
  }
  \lstloadlanguages{% Check Dokumentation for further languages ...
  	%[Visual]Basic
  	%Pascal
  	%C
  	%C++
  	%XML
  	%HTML
  	Python
  }
  %\DeclareCaptionFont{blue}{\color{blue}} 
  
  %\captionsetup[lstlisting]{singlelinecheck=false, labelfont={blue}, textfont={blue}}
  \usepackage{caption}
  
\DeclareCaptionFont{white}{\color{white}}
\DeclareCaptionFormat{listing}{\colorbox{gray}{\parbox{\textwidth}{#1#2#3}}}
\captionsetup[lstlisting]{format=listing,labelfont=white,textfont=white}

\hypersetup{
colorlinks=true,
filecolor =magenta,
urlcolor=magenta,
linkcolor=black,
citecolor=black,
runcolor=magenta	
}
\end_preamble
\use_default_options true
\begin_modules
eqs-within-sections
figs-within-sections
tabs-within-sections
\end_modules
\maintain_unincluded_children false
\language british
\language_package babel
\inputencoding latin9
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref true
\pdf_bookmarks true
\pdf_bookmarksnumbered false
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks false
\pdf_pdfborder true
\pdf_colorlinks false
\pdf_backref false
\pdf_pdfusetitle true
\papersize default
\use_geometry false
\use_amsmath 1
\use_esint 1
\use_mhchem 1
\use_mathdots 1
\cite_engine basic
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 2
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Section
Scientific Data Analysis
\end_layout

\begin_layout Standard
This section starts by giving an overview over the used scientific dataset
 in 4.1 and the data preparation described in 4.2.
 This includes sampling and feature extraction.
 This is followed by the Data Modelling in 4.3 and the Deployment with an
 IPython notebook in 4.4.
 
\end_layout

\begin_layout Subsection
Scientific Dataset
\end_layout

\begin_layout Standard
The data is not given as a table with numeric values and is an image-based
 dataset and therefore not directly useable for classification.
 It consists of two sets of images.
 The first one contains the original images of each cross section as RGB
 images (fig.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:original603"

\end_inset

).
 The second type is a mask for each of the different RGB images thus providing
 labelled data (fig.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:mask603"

\end_inset

), a gray scale image with only black or white pixels.
 A pixel is white if it belongs to the cross section and black if it does
 not.
 There are 
\begin_inset Formula $762$
\end_inset

 images (and additional 762 mask images) with a resolution of 
\begin_inset Formula $3272\times2469$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename graphics/mask200.png
	width 60line%

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Caption

\begin_layout Plain Layout
Mask of a cross section
\begin_inset CommandInset label
LatexCommand label
name "fig:mask603"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
As stated above there are two classes in total, so that the task is a binary
 classification problem.
 Before a classifier can be trained, the images have to be converted into
 a attribute value format and saved in a file.
 This could be a simple csv file or any other format that can handle numeric
 like data.
 In this case the libsvm format was chosen, because it is supported by many
 svm libraries, e.g.
 scikit-learn.
 Every row represents one instance, which is in this case one pixel and
 its features.
 Without applying any feature extraction method, the dataset (called A)
 has only the rgb values of a pixel from the original image and the class
 label from the mask.
 Listing 
\begin_inset CommandInset ref
LatexCommand ref
reference "libsvm"

\end_inset

 shows the libsvm format schematically.
 
\end_layout

\begin_layout Standard
\align center
\begin_inset listings
lstparams "float=h"
inline false
status open

\begin_layout Plain Layout
\align left

\begin_inset Caption

\begin_layout Plain Layout

libsvm format
\begin_inset CommandInset label
LatexCommand label
name "libsvm"

\end_inset


\end_layout

\end_inset

<class_label> <feature_id>:value ...
 <feature_id>:value
\end_layout

\begin_layout Plain Layout

<class_label> <feature_id>:value ...
 <feature_id>:value ...
 
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Data Preparation
\end_layout

\begin_layout Standard
In the first preprocessing step the image-based data is transformed into
 the libsvm format.
 The easiest method saves for each pixel the rgb values and the class label.
 This is done for every image resulting in 
\begin_inset Formula $762$
\end_inset

 files.
 Every file has 
\begin_inset Formula $8.078.568$
\end_inset

 instances, so there are 
\begin_inset Formula $6.155.868.816$
\end_inset

 pixels in total.
 The data preparation process in itself is already a challenging task for
 serial approaches and a time-consuming process.
 A first trivial approach took about 3 days to generate all attribute value
 files.
 The RGB values can be read directly from the original images.
 The class label is set to 
\begin_inset Formula $1$
\end_inset

 of the corresponding pixelvalue in the mask is greater than 
\begin_inset Formula $0$
\end_inset

.
 If this is not the case it is set to 
\begin_inset Formula $0$
\end_inset

.
 This was done with a python script, which was executed on Judge, a supercompute
r of the JSC with 
\begin_inset Formula $2472$
\end_inset

 nodes and 
\begin_inset Formula $412$
\end_inset

 graphic processors.
 The python script is started with a msub job submission script reserving
 one core with one node.
 To speed up the calculation time, the python script was changed so that
 it expects a range as parameters that says which image files it should
 convert.
 With this several independent jobs can be started with a different range
 argument resulting in a faster computation due to paralellization.
\end_layout

\begin_layout Standard
Building a model on the whole set would take a huge amount of time and is
 therefore unreasonable for creating a classifier.
 Instead of using the complete data set samples have to be used.
 As figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:mask603"

\end_inset

 shows there are more instances of class 
\begin_inset Formula $0$
\end_inset

 (black pixels) than of class 
\begin_inset Formula $1$
\end_inset

 (white pixels).
 To weight both classes equally, the sampled set is balanced.
 
\end_layout

\begin_layout Standard
The first approach is a balanced random sampling method.
 For a given percentage 
\begin_inset Formula $p$
\end_inset

 and a data set with 
\begin_inset Formula $N$
\end_inset

 instances the method draws 
\begin_inset Formula $p\cdot N$
\end_inset

 samples from a file.
 If the sample is balanced, 
\begin_inset Formula $p\cdot N\cdot0.5$
\end_inset

 instances of each class are drawn randomly.
 This can easily be parallelized since the files can be sampled independently.
 
\end_layout

\begin_layout Standard
An alternative method is to resize the images to a much smaller resolution
 (e.g.
 
\begin_inset Formula $256\times256$
\end_inset

 ).
 This is done for a number of images that are uniformly distributed among
 the different layers of the brain.
 An image has several different sections like the cross section, the brain
 in the background or the ice.
 If random sampling is used, it may happen that some of these sections are
 not represented by the sample.
 The lower the percentage 
\begin_inset Formula $p$
\end_inset

 is, the higher the chance gets that some sections is missed.
 
\end_layout

\begin_layout Standard
Because of this later samples were made by resizing the images.
 
\end_layout

\begin_layout Standard
This yields a first sample if dataset A.
 To improve the classifier the number of features has to be increased.
\end_layout

\begin_layout Subsubsection
HSV color space
\end_layout

\begin_layout Standard
A feature extraction method is used in order to provide more meaningful
 data to be used in learning the classifier.
 To increase the number of features another color space in addition to the
 given RGB values is used.
 In this case the HSV color space was chosen, because it is similiar to
 the human color vision.
 Furthermore it is used for object detection 
\begin_inset CommandInset citation
LatexCommand cite
key "shadowsuppression"

\end_inset

 because methods used on grayscale images can easily be used on images in
 the HSV space by using them on each color component.
 
\end_layout

\begin_layout Standard
The HSV color space has three components hue, saturation and value.
 The hue (H) is the angle on the chromatic circle and is therefore between
 
\begin_inset Formula $0$
\end_inset

 and 
\begin_inset Formula $360$
\end_inset

.
 The second and third components saturation (S) and lightness (V) are given
 in percentage, so their value is between 
\begin_inset Formula $0$
\end_inset

 and 
\begin_inset Formula $1$
\end_inset

 (or 
\begin_inset Formula $0-100\%$
\end_inset

).
 If the saturation is 
\begin_inset Formula $1$
\end_inset

, the color is clear.
 For a low saturation the color becomes gray.
 If the lightness is 
\begin_inset Formula $0$
\end_inset

, the color is black.
 
\end_layout

\begin_layout Standard
The values for a pixel can easily be transformed from RGB to HSV with the
 following formula:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray*}
Max & = & max(R,G,B)\\
Min & = & min(R,G,B)\\
H & = & \begin{cases}
0, & \text{if Max =Min \Leftrightarrow}R=G=B\\
60\text{°}\cdot\left(0+\frac{G-B}{Max-Min}\right) & \text{if Max =R }\\
60\text{°}\cdot\left(2+\frac{B-R}{Max-Min}\right) & \text{if Max =G}\\
60\text{°}\cdot\left(4+\frac{R-G}{Max-Min}\right) & \text{if Max =B}
\end{cases}\\
S & = & \begin{cases}
0 & \text{if Max =0 \Leftrightarrow R=G=B=0 }\\
\frac{Max-Min}{Max} & else
\end{cases}\\
V & = & Max
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Standard
Since this computation can be done independently for every pixel, the features
 can easily be computed in parallel and be added to existing data.
 While computing the HSV values is simple, they also add only few additional
 information.
 Dataset B has HSV features additional to the RGB features.
 
\begin_inset Note Comment
status open

\begin_layout Plain Layout
Because of this the increase of accuracy is only marginal.
\end_layout

\end_inset


\begin_inset Note Note
status open

\begin_layout Plain Layout
Kommentar muss in Evaluation
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{figure} 
\end_layout

\begin_layout Plain Layout


\backslash
centering 
\end_layout

\begin_layout Plain Layout


\backslash
includegraphics[width=0.7
\backslash
linewidth]{graphics/predict200_svm_rbf} 
\end_layout

\begin_layout Plain Layout


\backslash
caption{predicted image using svm with rbf kernel} 
\end_layout

\begin_layout Plain Layout


\backslash
label{fig:predict200_svm_rbf} 
\end_layout

\begin_layout Plain Layout


\backslash
end{figure}
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Local Features
\end_layout

\begin_layout Standard
Despite adding the HSV color space, there is still no information on the
 neighbourhood of a pixel that in many cases brings enormous results in
 classification accuracy of images (e.g.
 land-cover classification of remote sensing images 
\begin_inset CommandInset citation
LatexCommand cite
key "remote"

\end_inset

).
 A first level approach to get information on the neighbourhood of a pixel
 are statistical values like mean or standard deviation.
 The statistical values are calculated on an 
\begin_inset Formula $N\times N$
\end_inset

 array around a pixel and assigned to the centered pixel.
 This is done for every pixel of the image.
 Listing 
\begin_inset CommandInset ref
LatexCommand ref
reference "calc_std"

\end_inset

 shows how the standard deviation is calculated for an image.
 This is done with the numpy and scipy modules, which are optimized.
 
\end_layout

\begin_layout Standard
The 
\emph on
generic_filter
\emph default
 function generates a window with the given size for every pixel and calls
 the given function (e.g.
 numpy.std).
 However, the parameter of the called function is an one dimensional array.
 If the function needs a two dimensional one, it has to know the original
 shape of the window and reshape it.
 For most statistical measures this is not needed.
 The standard deviation is an indication for the homogenity of the pixel's
 neighbourhood.
\end_layout

\begin_layout Standard
\begin_inset listings
lstparams "basicstyle={\footnotesize\ttfamily},breaklines=true,caption={Calculate standard deviation},extendedchars=true,float,label={calc_std},language=Python,numbers=left,numberstyle={\tiny},showstringspaces=false,tabsize=2"
inline false
status open

\begin_layout Plain Layout

def calc_std(img,size,use_mean=False):     
\end_layout

\begin_layout Plain Layout

	"""Calculate the local standard deviation for each pixel of an image.
\end_layout

\begin_layout Plain Layout

    Arguments:
\end_layout

\begin_layout Plain Layout

        img : rgb image
\end_layout

\begin_layout Plain Layout

        size : size of the window of neighbouring pixels
\end_layout

\begin_layout Plain Layout

        use_mean : boolean, if False the standard deviation of R,G and B
 value are calculated and return as a 3 dimensional array.
\end_layout

\begin_layout Plain Layout

                   if True the standard deviation of the mean is returned.
\end_layout

\begin_layout Plain Layout

    Return:
\end_layout

\begin_layout Plain Layout

      array_like, 3d or 2d
\end_layout

\begin_layout Plain Layout

    """
\end_layout

\begin_layout Plain Layout

    if not use_mean:
\end_layout

\begin_layout Plain Layout

        std = np.zeros(img.shape)
\end_layout

\begin_layout Plain Layout

        for i in range(img.shape[2]):
\end_layout

\begin_layout Plain Layout

            std[:,:,i] = filters.generic_filter(img[:,:,i],np.std,size)
\end_layout

\begin_layout Plain Layout

    else:
\end_layout

\begin_layout Plain Layout

        mean_img = np.mean(img,axis=2)
\end_layout

\begin_layout Plain Layout

        std = filters.generic_filter(mean_img,np.std,size)
\end_layout

\begin_layout Plain Layout

    return std
\end_layout

\end_inset


\end_layout

\begin_layout Standard
By using the local standard deviation as a feature some first information
 of the neighbourhood is available.
 This can be further improved by other features.
\end_layout

\begin_layout Subsubsection
Image Segmentation
\end_layout

\begin_layout Standard
Watershed 
\begin_inset CommandInset citation
LatexCommand cite
key "watershed"

\end_inset

 is an image segmentation algorithm that is used on grayscale images.
 The gray level of a pixel is interpreted as its altitude and the image
 is seen as a ground.
 Water, that is filled into this ground from different markers, flows to
 a local minimum.
 
\end_layout

\begin_layout Standard
The algorithm floods basins from markers, which were set by the user.
 When two basins from different markers meet a watershed is drawn.
 The markers can be set in an easy way by using thresholds.
 While there are more complex ways using image processing methods, the threshold
 approach is used to keep the feature generation as simple as possible.
\end_layout

\begin_layout Standard
This yields a binary feature that is either one or zero and is used for
 training the classifier.
 Dataset C has RGB,HSV, standard deviation of RGB and watershed as features.
\end_layout

\begin_layout Subsection
Data Modeling
\end_layout

\begin_layout Subsubsection
Support Vector Machines
\end_layout

\begin_layout Standard
Support vector machines (SVMs) are one of the preferred classification methods
 lately, because tools are widely available and it is one of the best out-of-the
-box methods scientists can use that are not particularly trained in machine
 learning algorithms.
 They have a high accuracy, but their training time is quite long.
 A model can easily be described by the found support vectors.
 Fig 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:svm"

\end_inset

 shows a basic visualization of an SVM.
 On the left side a line is drawn that seperates both classes.
 This is the decision boundary.
 The right side is not linear separable.
 A kernel is used to push the data into a higher dimensional space, so that
 the classes are linear seperable in this space.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename graphics/linear_nonlinear.pdf
	width 70text%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Classification using Support Vector Machines.
 Linear expample on the left side (support vectors have a black border).
 Non linear example on the right side.
\begin_inset CommandInset label
LatexCommand label
name "fig:svm"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
A kernel defines the used scalar product.
 The most popular kernels are the following:
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{itemize} 
\end_layout

\begin_layout Plain Layout


\backslash
item linear:  $K(x,y) = 
\backslash
sum_{i=0}^n x_i
\backslash
cdot y_i$ 
\end_layout

\begin_layout Plain Layout


\backslash
item polynomial: $K(x,y) = (c+
\backslash
sum_{i=0}^{n} x_i
\backslash
cdot y_i)^d$	 	
\end_layout

\begin_layout Plain Layout


\backslash
item rbf: $ 
\backslash
exp(-
\backslash
frac{||x-y||^2}{2
\backslash
sigma^2})$  
\end_layout

\begin_layout Plain Layout


\backslash
end{itemize}  
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Unlike other classification methods (e.g.
 neural networks, naive bayes) SVMs need only a small training set in theory.
 Additional instances only affect the classifier if they contain new support
 vectors.
 However depending on the chosen kernel cross-validation runs are necessary
 to determine the parameter for the kernels (e.g.
 rbf works with parameter gamma).
\end_layout

\begin_layout Standard
More information on SVMs in general can be found at 
\begin_inset CommandInset citation
LatexCommand cite
key "Han2011"

\end_inset

.
\end_layout

\begin_layout Standard
Because support vector machines maximize the margin between the decision
 boundary and the support vectors, they do not overfit as easily as other
 classifiers like decision trees for example.
 However, solving the quadratic programming problem can have a complexity
 between 
\begin_inset Formula $O(n^{2})$
\end_inset

 and 
\begin_inset Formula $O(n^{3})$
\end_inset

 depending on the used algorithm and implementation.
 As figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "svm_table"

\end_inset

 shows training an svm takes much more time to be trained than other classifiers.
 This is especially true if a non linear kernel is used, e.g.
 rbf kernel.
 A linear svm is much faster but this goes along with a drop in accuracy.
 To get both a feasible training time and a good accuracy, a kernel approximatio
n is used together with a linear SVM.
 A kernel approximation is used before training a SVM (see listing 
\begin_inset CommandInset ref
LatexCommand ref
reference "kernel approximation"

\end_inset

).
 It adds additional random features to the data.
 For the rbf kernel this is done by a Monte Carlo approximation of its Fourier
 transform.
 More information on random fourier features and random binning features
 can be found at 
\begin_inset CommandInset citation
LatexCommand cite
key "Rahimi"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset listings
lstparams "caption={kernel approximation using scikti learn},float,label={kernel approximation},language=Python"
inline false
status open

\begin_layout Plain Layout

from sklearn.kernel_approximation import RBFSampler
\end_layout

\begin_layout Plain Layout

rbf = RBFSampler(gamma=2) 
\end_layout

\begin_layout Plain Layout

X_features = rbf.fit_transform(X_train) 
\end_layout

\begin_layout Plain Layout

X_test_features = rbf.transform(X_test)
\end_layout

\end_inset


\end_layout

\begin_layout Standard
A second approach is the Nystroem method 
\begin_inset CommandInset citation
LatexCommand cite
key "Williams01usingthe"

\end_inset

 which can approximate every kernel and not only the rbf one.
 It uses a subsample of the data set to approximate a kernel.
 As 
\begin_inset CommandInset citation
LatexCommand cite
key "NIPS2012_4588"

\end_inset

 shows the nyström method can achieve a better generalization in some cases.
 
\begin_inset Note Comment
status open

\begin_layout Plain Layout
For the brain analytics use case however this could not be noted.
\end_layout

\end_inset


\begin_inset Note Note
status open

\begin_layout Plain Layout
Evaluation
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Other Classifiers
\end_layout

\begin_layout Standard
There are some other classifiers besides support vector machines.
 While the focus is on SVMs and they were optimized the most, some models
 with other classifiers were tested too.
 Naive Bayes is one of them.
 Due to its simplicity it is quite fast.
 Unfortunately the accuracy score is not good since Naive Bayes assumes
 independency of features which is obiously not the cause for RGB values
 of an image.
 
\end_layout

\begin_layout Standard
While KNearestNeighbour considers feature dependencies and therefore has
 a higher accuracy, it's training time is also higher than the one of naive
 bayes.
 Apart from that figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "different_classifiers_table"

\end_inset

 shows that the prediction takes much longer since the distances to all
 instances have to be calculated.
\end_layout

\begin_layout Standard
Decision trees without any pruning or ensemble methods have a better accuracy
 than naive bayes as well but not as good as KNN.
 While their training time is larger than the one of naive bayes, it is
 way faster than KNN.
 For the random forest classifier, which uses ten randomized decision trees,
 the accuracy as well as the training and testing time increase.
\end_layout

\begin_layout Standard
\begin_inset Float table
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="6" columns="4">
<features tabularvalignment="middle">
<column alignment="left" valignment="top" width="0">
<column alignment="right" valignment="top" width="0">
<column alignment="right" valignment="top" width="0">
<column alignment="right" valignment="top" width="0">
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Classifier
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Accuracy
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
training time in s
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
test time in s
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Decision Tree
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0.9569552165$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0.563767$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0.057934$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Random Forest
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0.9637635858$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $1.698716$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0.399092$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
KNN
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0.9677196684$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $1.57$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $5.29$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
GaussianNB
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0.9475908597$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0.042224$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0.075098$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
SVM
\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0.9579808675$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $45.242423$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="right" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $66.846724$
\end_inset


\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\begin_inset Caption

\begin_layout Plain Layout
Different classifiers used on Dataset A,
\begin_inset Formula $0.1\%$
\end_inset

 sample.
\begin_inset CommandInset label
LatexCommand label
name "different_classifiers_table"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Multiple Models
\end_layout

\begin_layout Standard
With only one model for all the different cross section the prediction is
 not very good for some cross sections.
 While it is not reasonable to use the x and y coordinates of a pixel as
 features because the brains position changes between the images, it is
 possible to use the z axis as a feature.
 The z position of an image is contained in its file name, since all the
 images are numbered.
 Naturally, for this to work future cross sections have to be numbered in
 the same way.
 The alternative to use the z position as a feature with one model is to
 divide the brain in several layers and create a model for every layer.
 This however could have impacts for the classification of future brains
 that might differ in volume, orientation, and location of brain elements.
\end_layout

\begin_layout Standard
There are also advantages in comparison to using one model.
 By increasing the number of models each single model is simpler.
 It also decreases the training time.
 This has two reasons.
 The first is that the amount of training data for each model is less because
 the data is sliced into different layers.
 In addition the training of the models can easily be parallelized because
 they are completely independent from each other.
 
\end_layout

\begin_layout Standard
\begin_inset Note Comment
status open

\begin_layout Plain Layout
Using multiple models can also be useful if the color between the different
 layers varies slightly.
\end_layout

\end_inset


\begin_inset Note Note
status open

\begin_layout Plain Layout
RauS? Umformulieren: not sure this gives a lower generalization error when
 considering new 5 human brains to classify...
 seems "overfit" in a sense...
 
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Grid Search
\end_layout

\begin_layout Standard
While scikit-learn already implements a function that performs grid search
 on a given set of parameters and a classifier, this function can not be
 used if kernel approximation is used as well.
 The parameters that have to be optimized are the penalty parameter 
\begin_inset Formula $C$
\end_inset

 and kernel coefficient 
\begin_inset Formula $\gamma$
\end_inset

.
 If kernel approximation is used, the linear SVM does not expect an argument
 
\begin_inset Formula $\gamma$
\end_inset

.
 Instead 
\begin_inset Formula $\gamma$
\end_inset

 is set in the RBFSampler.
 Therefore the scikit-learn function can not be used and a modified version
 was implemented.
 The new version generates a new data set C* with the additional features
 and the current 
\begin_inset Formula $\gamma$
\end_inset

.
 Thereafter a linear SVM is trained with the given 
\begin_inset Formula $C$
\end_inset

 and cross validated.
 All results are saved in a list and returned.
 To speed up the grid search, it is parallized with IPython using the LoadBalanc
edView.
 Unlike the DirectView interface this one does not allow direct access to
 the individual engines.
 Instead of that the IPython scheduler assigns the tasks to the engines
 minimizing the idle time of the engines.
 Because of this the grid search can not only be used on a single machine
 but on clusters, if the IPython cluster is setup.
 
\end_layout

\begin_layout Standard
\begin_inset Float table
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="4" columns="4">
<features tabularvalignment="middle">
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $g=0.1,C=1$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $g=0.1,C=10$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $g=0.1,C=100$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $g=0.1,C=1000$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $g=0.25,C=1$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $g=0.25,C=10$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $g=0.25,C=100$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $g=0.25,C=1000$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $g=0.5,C=1$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $g=0.5,C=10$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $g=0.5,C=100$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $g=0.5,C=1000$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $g=1,C=1$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $g=1,C=10$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $g=1,C=100$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $g=1,C=1000$
\end_inset


\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Parameter space for a grid search on set C 
\begin_inset CommandInset label
LatexCommand label
name "tab:gridsearch"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Deployment
\end_layout

\begin_layout Standard
In this section the deployment is described as a so called IPython notebook.
 It contains the complete workflow from data preprocessing to model evaluation
 as well as some explanations and comments.
 This allows a scientist to easily change and use the functions he needs.
 
\end_layout

\begin_layout Standard
The following part can also be watched as a html 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
href{run:./FullRun.html}{file}
\end_layout

\end_inset

 or opened using the 
\emph on
ipython notebook FullRun.ipynb
\emph default
 command.
 
\end_layout

\begin_layout Subsubsection
Setup
\end_layout

\begin_layout Standard
This notebook shows the different steps that are needed to classify the
 brain cross sections.
 It starts with the data preprocessing and ends with a final model.
 Several different functions are used by the imported custom modules.
 This is done, so that the notebook stays clear.
 If you want to take a detailed look at the used functions, feel free to
 use the different source files.
\end_layout

\begin_layout Standard
At the beginning the client is set up, so that the engines can be accessed
 and used.
\end_layout

\begin_layout Standard
\begin_inset listings
lstparams "breaklines=true,caption={Client Setup},float=h,language=Python,numbers=left"
inline false
status open

\begin_layout Plain Layout

# Import the client and the imp module to load source files on all engines
 
\end_layout

\begin_layout Plain Layout

from IPython.parallel import Client
\end_layout

\begin_layout Plain Layout

c = Client() dview = c[:] 
\end_layout

\begin_layout Plain Layout

dview.block = True 
\end_layout

\begin_layout Plain Layout

with dview.sync_imports():     
\end_layout

\begin_layout Plain Layout

	import imp
\end_layout

\end_inset


\end_layout

\begin_layout Standard
The training data can be sampled.
 In this example this is done by rescaling some images to a size of 256x256.
\end_layout

\begin_layout Standard
\begin_inset listings
lstparams "breaklines=true,caption={Generating samples},float=h,language=Python,numbers=left"
inline false
status open

\begin_layout Plain Layout

# resizing the images 
\end_layout

\begin_layout Plain Layout

import glob masks = glob.glob("../classification/data/rescaled256x256/masks/MSA*.tif
") 
\end_layout

\begin_layout Plain Layout

images = glob.glob("../classification/data/rescaled256x256/images/MSA*.tif")
\end_layout

\begin_layout Plain Layout

from PIL import Image
\end_layout

\begin_layout Plain Layout

size=(256,256) 
\end_layout

\begin_layout Plain Layout

resized_images = [Image.open(i).resize(size) for i in images] 
\end_layout

\begin_layout Plain Layout

resized_masks = [Image.open(m).resize(size) for m in images]
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Feature Extraction and Sampling
\end_layout

\begin_layout Standard
The following code block shows how to generate libsvm formated data from
 an original image and the hand labeled mask.
 This is done on multiple engines started by ipython.
 In this example the used features are: 
\end_layout

\begin_layout Standard
\begin_inset Formula $R,G,B,std(R),std(G),std(B),segmentationbit,H,S,V$
\end_inset


\end_layout

\begin_layout Standard
The window size for the image is 16x16 pixel.
 The thresholds for watershed segmentation are set as p=0.2 and q=0.8.
 Custom features can be added easily.
 A feature that needs the original image needs to be set in the new_features
 list.
 If only the pixel is needed, the online_feature list is sufficient.
 
\end_layout

\begin_layout Standard
Because callables are passed, the user can add any new function.
 The only condition is that the first argument is the image/pixel.
 If the function has more arguments, the 
\emph on
partial
\emph default
 function can be used to create a new one with only one argument.
\end_layout

\begin_layout Standard
\begin_inset listings
lstparams "breaklines=true,caption={Converting and Adding Features},float=h,language=Python,numbers=left,showstringspaces=false"
inline false
status open

\begin_layout Plain Layout

# load data conversion and feature extration modules locally and on the
 engines 
\end_layout

\begin_layout Plain Layout

dc = imp.load_source("data_conversion","../parallel/data_generation/data_conversion.
py") 
\end_layout

\begin_layout Plain Layout

fe = imp.load_source("feature_extraction","../classification/feature_extraction.py")
 
\end_layout

\begin_layout Plain Layout

# use the direct view to load the modules 
\end_layout

\begin_layout Plain Layout

dview.execute('dc = imp.load_source("data_conversion","../parallel/data_generation/d
ata_conversion.py")') 
\end_layout

\begin_layout Plain Layout

dview.execute('fe = imp.load_source("feature_extraction","../classification/feature_
extraction.py")')
\end_layout

\begin_layout Plain Layout

# set masks and images, that are to be converted, as lists 
\end_layout

\begin_layout Plain Layout

# be aware that masks[0] must belong to images[0].
 This is done by sorting the lists 
\end_layout

\begin_layout Plain Layout

import glob 
\end_layout

\begin_layout Plain Layout

masks = sorted(glob.glob("../classification/data/rescaled256x256/masks/MSA*.tif"))
 
\end_layout

\begin_layout Plain Layout

images = sorted(glob.glob("../classification/data/rescaled256x256/images/MSA*.tif"))
\end_layout

\begin_layout Plain Layout

# scatter the images and mask to the engines 
\end_layout

\begin_layout Plain Layout

dview.scatter("images",images) 
\end_layout

\begin_layout Plain Layout

dview.scatter("masks",masks)
\end_layout

\begin_layout Plain Layout

with dview.sync_imports():     
\end_layout

\begin_layout Plain Layout

	from functools import partial
\end_layout

\begin_layout Plain Layout

# add features and convert the images 
\end_layout

\begin_layout Plain Layout

out_dir = "../classification/data/rescaled256x256/test" 
\end_layout

\begin_layout Plain Layout

dview['out_dir'] = out_dir 
\end_layout

\begin_layout Plain Layout

cmd = 'dc.convert_and_save(images,masks,out_dir,new_features=[partial(fe.calc_std,
size=16),partial(fe.findSegmentation,p=0.2)],online_features=[fe.add_hsv])'
\end_layout

\begin_layout Plain Layout

dview.execute(cmd)
\end_layout

\end_inset


\end_layout

\begin_layout Standard
The data can be combined into training and testing sets.
 The data is shuffled and the sets are class balanced by default.
 The 
\emph on
combine_files
\emph default
 method can be used to generate training sets for the different layers,
 if multiple models are used.
 
\end_layout

\begin_layout Standard
\begin_inset listings
lstparams "breaklines=true,caption={Create training and testing sets},float=h,language=Python,numbers=left"
inline false
status open

\begin_layout Plain Layout

sampling = imp.load_source("sample_files","../data_generation/random_sampling/sampl
e_files.py") 
\end_layout

\begin_layout Plain Layout

sampling.OUT = "../classification/data/rescaled256x256/test"
\end_layout

\begin_layout Plain Layout

sampling.combine_files("../classification/data/rescaled256x256/test/","ALL.svm")
 
\end_layout

\begin_layout Plain Layout

sampling.split_train_test("../classification/data/rescaled256x256/test/","ALL.svm",t
est_size=0.5,shuffle=True)
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Creating a Model
\end_layout

\begin_layout Standard
To build a classifier, first the training and test data have to be loaded.
 In this case it is a single cross section, but any combination of the different
 images can be used.
 This can be done with 
\emph on
sample.combine_files
\emph default
.
\end_layout

\begin_layout Standard
The data is normalized and additional features are added.
 Instead of the RBFSampler the Nystroem method can be used to generate different
 features or approximate another kernel.
\end_layout

\begin_layout Standard
At the end the classifier is trained with parameters optimized with a grid
 search.
 Instead of building one classifier, grid search may be used to test different
 parameters on the current data set.
 After this the model can easily be saved with the pickle module which is
 part of the python standard library.
 It can also be used to save the RBFSampler which is needed if new data
 should be predicted.
\end_layout

\begin_layout Standard
\begin_inset listings
lstparams "breaklines=true,caption={Build a SVM classifier},float=h,language=Python,numbers=left"
inline false
status open

\begin_layout Plain Layout

from skimage.io import imshow,imread 
\end_layout

\begin_layout Plain Layout

import numpy as np 
\end_layout

\begin_layout Plain Layout

from sklearn.kernel_approximation import RBFSampler 
\end_layout

\begin_layout Plain Layout

from sklearn.svm import LinearSVC 
\end_layout

\begin_layout Plain Layout

from sklearn.datasets import load_svmlight_file
\end_layout

\begin_layout Plain Layout

# load training set 
\end_layout

\begin_layout Plain Layout

X_train,y_train = load_svmlight_file("../classification/data/rescaled256x256/MSA_0
3-2009_dXXXX-XX-XX_s0110.svm") 
\end_layout

\begin_layout Plain Layout

X_train = X_train.toarray()
\end_layout

\begin_layout Plain Layout

# normalize data 
\end_layout

\begin_layout Plain Layout

max_val = X_train.max(axis=0) 
\end_layout

\begin_layout Plain Layout

min_val = X_train.min(axis=0) 
\end_layout

\begin_layout Plain Layout

X_train = (X_train-min_val)/(max_val-min_val)
\end_layout

\begin_layout Plain Layout

# load test image 
\end_layout

\begin_layout Plain Layout

X_test,y_test = load_svmlight_file("../classification/data/segmentation/MSA_03-200
9_dXXXX-XX-XX_s0200.svm") 
\end_layout

\begin_layout Plain Layout

X_test = X_test.toarray() 
\end_layout

\begin_layout Plain Layout

X_test = (X_test-min_val)/(max_val-min_val)
\end_layout

\begin_layout Plain Layout

# generate additional features 
\end_layout

\begin_layout Plain Layout

rbf = RBFSampler(gamma=2) 
\end_layout

\begin_layout Plain Layout

X_features = rbf.fit_transform(X_train) 
\end_layout

\begin_layout Plain Layout

X_test_features = rbf.transform(X_test)
\end_layout

\begin_layout Plain Layout

# train linear SVM on highdimensional data 
\end_layout

\begin_layout Plain Layout

linearSVM = LinearSVC(dual=False,C=1000000) 
\end_layout

\begin_layout Plain Layout

linearSVM.fit(X_features,y_train)
\end_layout

\begin_layout Plain Layout

# save model  
\end_layout

\begin_layout Plain Layout

import pickle with open("SVMClassifier.pkl","w") as f:
\end_layout

\begin_layout Plain Layout

    pickle.dump(linearSVM,f)
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Predicting new Data
\end_layout

\begin_layout Standard
If the classifier is not trained in the current session, it can be loaded
 with the pickle module.
 After adding the random features the class can be predicted using the 
\emph on
predict
\emph default
 method of the classifier.
 The predicted labels can be reshaped, so that the new mask can be printed.
\end_layout

\begin_layout Standard
\begin_inset listings
lstparams "breaklines=true,caption={Classify test image},float=h,language=Python,numbers=left"
inline false
status open

\begin_layout Plain Layout

# load model 
\end_layout

\begin_layout Plain Layout

import pickle 
\end_layout

\begin_layout Plain Layout

with open("SVMClassifier.pkl","r") as f:
\end_layout

\begin_layout Plain Layout

    linearSVM = pickle.load(f)     
\end_layout

\begin_layout Plain Layout

# load hand labeled mask 
\end_layout

\begin_layout Plain Layout

mask = imread("../classification/data/segmentation/masks/MSA_03-2009_dXXXX-XX-XX_s
0200.tif")
\end_layout

\begin_layout Plain Layout

labels = linearSVM.predict(X_test_features) 
\end_layout

\begin_layout Plain Layout

labels = labels.reshape(mask.shape)
\end_layout

\begin_layout Plain Layout

%matplotlib inline 
\end_layout

\begin_layout Plain Layout

imshow(labels)
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename graphics/FullRun_17_0.png
	width 50text%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
predicted mask
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Postprocessing the results
\end_layout

\begin_layout Standard
If the data is also labeled by hand, the quality of the model can be measured.
 The following function calculates the accuracy as well as the f-score.
 It also returns the confusion matrix.
 
\end_layout

\begin_layout Standard
Because the classified data is an image, the confusion matrix is visualized
 as an image.
 All true positives are colored white and all true negatives black.
 With 100% accuracy this would result in the hand labeled mask.
 Since this is most often not the case, all false positives are marked red
 and all false negatives blue.
 
\end_layout

\begin_layout Standard
This gives a good first impression on the quality of the classifier.
 If the predicted labels are post processed by hand, it furthermore gives
 an indication which regions cause problems.
 
\end_layout

\begin_layout Standard
\begin_inset listings
lstparams "breaklines=true,caption=Postprocessing,float=h,language=Python,numbers=left"
inline false
status open

\begin_layout Plain Layout

from sklearn.metrics import confusion_matrix,f1_score,accuracy_score 
\end_layout

\begin_layout Plain Layout

from collections import namedtuple
\end_layout

\begin_layout Plain Layout

AccuracyMetrics = namedtuple('AccuracyMetrics',['accuracy','fscore','confusion_m
atrix','image'])
\end_layout

\begin_layout Plain Layout

def compare_to_mask(pred,mask):
\end_layout

\begin_layout Plain Layout

    size = pred.shape
\end_layout

\begin_layout Plain Layout

    img = np.zeros((mask.shape[0],mask.shape[1],3),dtype='uint8')
\end_layout

\begin_layout Plain Layout

    tp = np.dstack(((pred>0).reshape(size),(mask>0).reshape(size)))
\end_layout

\begin_layout Plain Layout

    fp = np.dstack(((pred>0).reshape(size),(mask==0).reshape(size)))
\end_layout

\begin_layout Plain Layout

    fn = np.dstack(((pred==0).reshape(size),(mask>0).reshape(size)))
\end_layout

\begin_layout Plain Layout

    img[np.all(tp,axis=2),:] = 255
\end_layout

\begin_layout Plain Layout

    img[np.all(fp,axis=2),0] = 255
\end_layout

\begin_layout Plain Layout

    img[np.all(fn,axis=2),2] = 255
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    acc = accuracy_score(mask.flatten(),pred.flatten(),normalize=True)
\end_layout

\begin_layout Plain Layout

    fscore = f1_score(mask.flatten(),pred.flatten())
\end_layout

\begin_layout Plain Layout

    cm = confusion_matrix(mask.flatten(),pred.flatten())
\end_layout

\begin_layout Plain Layout

    return AccuracyMetrics(acc,fscore,cm,img)
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

metrics = compare_to_mask(labels,y_test.reshape(labels.shape)) 
\end_layout

\begin_layout Plain Layout

imshow(metrics[3])
\end_layout

\end_inset


\end_layout

\end_body
\end_document
