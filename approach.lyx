#LyX 2.0 created this file. For more info see http://www.lyx.org/
\lyxformat 413
\begin_document
\begin_header
\textclass scrartcl
\begin_preamble
\usepackage{graphicx}
\usepackage{listings}
\usepackage{color}
\usepackage{xcolor}
\usepackage{caption}
\usepackage{url}

  \usepackage{courier}
  \lstset{
  	basicstyle=\footnotesize\ttfamily, % Standardschrift
  	%numbers=left,               % Ort der Zeilennummern
  	numberstyle=\tiny,          % Stil der Zeilennummern
  	%stepnumber=2,               % Abstand zwischen den Zeilennummern
  	numbersep=5pt,              % Abstand der Nummern zum Text
  	tabsize=2,                  % Groesse von Tabs
  	extendedchars=true,         %
  	breaklines=true,            % Zeilen werden Umgebrochen
  	keywordstyle=\color{red},
  	frame=b,         
  	%        keywordstyle=[1]\textbf,    % Stil der Keywords
  	%        keywordstyle=[2]\textbf,    %
  	%        keywordstyle=[3]\textbf,    %
  	%        keywordstyle=[4]\textbf,   \sqrt{\sqrt{}} %
  	stringstyle=\color{white}\ttfamily, % Farbe der String
  	showspaces=false,           % Leerzeichen anzeigen ?
  	showtabs=false,             % Tabs anzeigen ?
  	xleftmargin=17pt,
  	framexleftmargin=17pt,
  	framexrightmargin=5pt,
  	framexbottommargin=4pt,
  	%backgroundcolor=\color{lightgray},
  	showstringspaces=false      % Leerzeichen in Strings anzeigen ?        
  }
  \lstloadlanguages{% Check Dokumentation for further languages ...
  	%[Visual]Basic
  	%Pascal
  	%C
  	%C++
  	%XML
  	%HTML
  	Java
  }
  %\DeclareCaptionFont{blue}{\color{blue}} 
  
  %\captionsetup[lstlisting]{singlelinecheck=false, labelfont={blue}, textfont={blue}}
  \usepackage{caption}
  
\DeclareCaptionFont{white}{\color{white}}
\DeclareCaptionFormat{listing}{\colorbox{gray}{\parbox{\textwidth}{#1#2#3}}}
\captionsetup[lstlisting]{format=listing,labelfont=white,textfont=white}
\end_preamble
\use_default_options true
\begin_modules
eqs-within-sections
figs-within-sections
tabs-within-sections
\end_modules
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\float_placement H
\paperfontsize default
\spacing single
\use_hyperref true
\pdf_bookmarks true
\pdf_bookmarksnumbered false
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks false
\pdf_pdfborder true
\pdf_colorlinks false
\pdf_backref false
\pdf_pdfusetitle true
\papersize default
\use_geometry false
\use_amsmath 1
\use_esint 1
\use_mhchem 1
\use_mathdots 1
\cite_engine basic
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Section
Approach
\end_layout

\begin_layout Subsection
The Data
\end_layout

\begin_layout Standard
The data is not given as a classic table and therefor not directly useable
 for classification.
 It consists of two sets of images.
 The first one contains the original images of each cross section and a
 corresponding mask.
 A mask is a grayscale image with only black or white pixels.
 A pixel is white if it belongs to the cross section and black if it does
 not.
 There are 
\begin_inset Formula $762$
\end_inset

 images with a resolution of 
\begin_inset Formula $3272\times2469$
\end_inset

, resulting in a huge amount of pixels.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{lstlisting}[caption=libsvm format,label=lisbsvm] 
\end_layout

\begin_layout Plain Layout

<class_label> <feature_id>:value ...
 <feature_id>:value
\end_layout

\begin_layout Plain Layout

<class_label> <feature_id>:value ...
 <feature_id>:value ...
 
\end_layout

\begin_layout Plain Layout


\backslash
end{lstlisting} 
\end_layout

\end_inset


\end_layout

\begin_layout Standard
The classification problem is a binary one since there are only two classes.
 Before a classifier can be trained, the images have to be converted into
 a attribute value format.
 The libsvm format was chosen, because it is well known and many libraries
 support it.
 Every row represents one instance, which is in this case one pixel and
 its features.
 Currently the only features available are the rgb values of a pixel from
 the original image and the class label from the mask.
 
\end_layout

\begin_layout Subsection
Data Preparation
\end_layout

\begin_layout Standard
In the first preprocessing step the libsvm data is created.
 The easiest method saves for each pixel the rgb values and the class label.
 This is done for every image resulting in 
\begin_inset Formula $762$
\end_inset

 files.
 Every file has 
\begin_inset Formula $8.078.568$
\end_inset

 instances, so there are 
\begin_inset Formula $6.155.868.816$
\end_inset

 pixels in total.
 A first trivial approach took about 3 days to generate all attribute value
 files.
\end_layout

\begin_layout Standard
Building a model on this set would take a huge amount of time and is therefor
 unreasonable for selecting a model.
 Instead of using the complete data set samples have to be used.
 As figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:mask603"

\end_inset

 shows there are more instances of class 
\begin_inset Formula $0$
\end_inset

 (black pixels) than of class 
\begin_inset Formula $1$
\end_inset

 (white pixels).
 To weight both classes equally, the sampled set is balanced.
 
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{figure}	
\end_layout

\begin_layout Plain Layout


\backslash
centering 	
\end_layout

\begin_layout Plain Layout


\backslash
includegraphics[width=0.6
\backslash
linewidth]{graphics/mask603} 	
\end_layout

\begin_layout Plain Layout


\backslash
caption{Mask of a cross section} 	
\end_layout

\begin_layout Plain Layout


\backslash
label{fig:mask603} 
\end_layout

\begin_layout Plain Layout


\backslash
end{figure}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
The first approach is a balanced random sampling method.
 For a given percentage 
\begin_inset Formula $p$
\end_inset

 and a data set with $N$ instances the method draws 
\begin_inset Formula $p\cdot N$
\end_inset

 samples from a file.
 If the sample is balanced, 
\begin_inset Formula $p\cdot N\cdot0.5$
\end_inset

 instances of each class are drawn randomly.
 This can easily be parallelized since the files can be sampled independently.
 This yields a first sample with three features.
 To improve the classifier the number of features has to be increased.
\end_layout

\begin_layout Subsubsection
HSV color space
\end_layout

\begin_layout Standard
An easy method to increase the number of features is to use another color
 space in addition to the given RGB values.
 In this case the HSV color space was chosen.
 It represents a color by its hue, saturation and value.
 The values for a pixel can easily be transformed from RGB to HSV with the
 following formula:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray*}
Max & = & max(R,G,B)\\
Min & = & min(R,G,B)\\
H & = & \begin{cases}
0, & \text{if Max =Min \Leftrightarrow}R=G=B\\
60\text{°}\cdot\left(0+\frac{G-B}{Max-Min}\right) & \text{if Max =R }\\
60\text{°}\cdot\left(2+\frac{B-R}{Max-Min}\right) & \text{if Max =G}\\
60\text{°}\cdot\left(4+\frac{R-G}{Max-Min}\right) & \text{if Max =B}
\end{cases}\\
S & = & \begin{cases}
0 & \text{if Max =0 \Leftrightarrow R=G=B=0 }\\
\frac{Max-Min}{Max} & else
\end{cases}\\
V & = & Max
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Standard
Since this computation can be done independently for every pixel, the features
 can easily be computed in parallel and be added to existing data.
 While computing the HSV values is simple, they also add only few additional
 information.
 Because of this the increase of accuracy is only marginal.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{figure} 
\end_layout

\begin_layout Plain Layout


\backslash
centering 
\end_layout

\begin_layout Plain Layout


\backslash
includegraphics[width=0.7
\backslash
linewidth]{graphics/predict200_svm_rbf} 
\end_layout

\begin_layout Plain Layout


\backslash
caption{predicted image using svm with rbf kernel} 
\end_layout

\begin_layout Plain Layout


\backslash
label{fig:predict200_svm_rbf} 
\end_layout

\begin_layout Plain Layout


\backslash
end{figure}
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Local Features
\end_layout

\begin_layout Standard
Despite adding the HSV color space, there is still no information on the
 neighbourhood of a pixel.
 A first level approach to get information on the neighbourhood of a pixel
 are statistical values like mean or standard deviation.
 The statistical values are calculated on an 
\begin_inset Formula $N\times N$
\end_inset

 array around a pixel and assigned to the centered pixel.
 Listing 
\begin_inset CommandInset ref
LatexCommand ref
reference "calc_std"

\end_inset

 shows how the standard deviation is calculated for an image.
 This is done with the numpy and scipy modules.
 The 
\emph on
generic_filter
\emph default
 function generates a window with the given size for every pixel and calls
 the given function (e.g.
 numpy.std).
 The standard deviation is an indication for the homogenity of the pixel's
 neighbourhood.
\end_layout

\begin_layout Standard
\begin_inset listings
lstparams "basicstyle={\footnotesize\ttfamily},breaklines=true,caption={Calculate standard deviation},extendedchars=true,label={calc_std},language=Python,numbers=left,numberstyle={\tiny},showstringspaces=false,tabsize=2"
inline false
status open

\begin_layout Plain Layout

def calc_std(img,size,use_mean=False):     
\end_layout

\begin_layout Plain Layout

	"""Calculate the local standard deviation for each pixel of an image.
\end_layout

\begin_layout Plain Layout

    Arguments:
\end_layout

\begin_layout Plain Layout

        img : rgb image
\end_layout

\begin_layout Plain Layout

        size : size of the window of neighbouring pixels
\end_layout

\begin_layout Plain Layout

        use_mean : boolean, if False the standard deviation of R,G and B
 value are calculated and return as a 3 dimensional array.
\end_layout

\begin_layout Plain Layout

                    if True the standard deviation of the mean is returned.
\end_layout

\begin_layout Plain Layout

    Return:
\end_layout

\begin_layout Plain Layout

      array_like, 3d or 2d
\end_layout

\begin_layout Plain Layout

    """
\end_layout

\begin_layout Plain Layout

    if not use_mean:
\end_layout

\begin_layout Plain Layout

        std = np.zeros(img.shape)
\end_layout

\begin_layout Plain Layout

        for i in range(img.shape[2]):
\end_layout

\begin_layout Plain Layout

            std[:,:,i] = filters.generic_filter(img[:,:,i],np.std,size)
\end_layout

\begin_layout Plain Layout

    else:
\end_layout

\begin_layout Plain Layout

        mean_img = np.mean(img,axis=2)
\end_layout

\begin_layout Plain Layout

        std = filters.generic_filter(mean_img,np.std,size)
\end_layout

\begin_layout Plain Layout

    return std
\end_layout

\end_inset


\end_layout

\begin_layout Standard
By using the local standard deviation as a feature some information of the
 neighbourhood is used, but this can be improved with other features.
\end_layout

\begin_layout Subsubsection
Image Segmentation
\end_layout

\begin_layout Standard
A more complex feature can be achieved by performing watershed segmentation.
 It is used on grayscale images and the pixel values are treated as a elevation.
 The algorithm floods basins from markers, which were set by the user.
 When two basins from different markers meet a watershed is drawn.
 The markers can be set in an easy way by using thresholds.
 While there are more complex ways using image processing methods, the threshold
 approach is used to keep the feature generation simple.
\end_layout

\begin_layout Subsection
Data Modeling
\end_layout

\begin_layout Subsubsection
Support Vector Machines
\end_layout

\begin_layout Standard
Support vector machines (SVMs) are one of the preferred classification methods
 lately.
 They have a high accuracy, but their training time is quite long.
 A model can easily be described by the found support vectors.
\end_layout

\begin_layout Standard
SVMs can model nonlinear decision boundaries by using other kernels instead
 of the linear kernel to increase the dimension of a vector.
 A kernel defines the used scalar product.
 The most popular kernels are the following:
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{itemize} 
\end_layout

\begin_layout Plain Layout


\backslash
item linear:  $K(x,y) = 
\backslash
sum_{i=0}^n x_i
\backslash
cdot y_i$ 
\end_layout

\begin_layout Plain Layout


\backslash
item polynomial: $K(x,y) = (c+
\backslash
sum_{i=0}^{n} x_i
\backslash
cdot y_i)^d$	 	
\end_layout

\begin_layout Plain Layout


\backslash
item rbf: $ 
\backslash
exp(-
\backslash
frac{||x-y||^2}{2
\backslash
sigma^2})$  
\end_layout

\begin_layout Plain Layout


\backslash
end{itemize}  
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{figure}
\end_layout

\begin_layout Plain Layout


\backslash
begin{tabular}{|l|r|r|r|}
\end_layout

\begin_layout Plain Layout


\backslash
hline 	
\end_layout

\begin_layout Plain Layout

Classifier 	& Accuracy & training time in s & test time in s 
\backslash

\backslash
  	
\end_layout

\begin_layout Plain Layout


\backslash
hline 	
\end_layout

\begin_layout Plain Layout


\backslash
hline 	
\end_layout

\begin_layout Plain Layout

SVC (sklearn), rbf, 20k instances 	& 0.8752580408 	& 39.545465 	& 109.808209
 	
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline 	
\end_layout

\begin_layout Plain Layout


\backslash
parbox[t]{6cm}{SVC (sklearn), rbf,
\backslash

\backslash
 gamma=0.1, C=1, 20k instances} 	& 0.9579808675 	& 45.242423 	& 66.846724 
\backslash

\backslash
  	
\end_layout

\begin_layout Plain Layout


\backslash
hline 	
\end_layout

\begin_layout Plain Layout

libSVM twister, 20k instances 	& 0.9592930497 	& 445.867 	& - 
\backslash

\backslash
  	
\end_layout

\begin_layout Plain Layout


\backslash
hline 	
\end_layout

\begin_layout Plain Layout

libSVM twister, 40k instances 	& 0.963317509 	& 934.912 	& - 
\backslash

\backslash
  	
\end_layout

\begin_layout Plain Layout


\backslash
hline 	
\end_layout

\begin_layout Plain Layout

libSVM twister, 100k instances 	& 0.9665214475 	& 3077.239 	& -
\backslash

\backslash
 	
\end_layout

\begin_layout Plain Layout


\backslash
hline 
\end_layout

\begin_layout Plain Layout


\backslash
end{tabular}  
\end_layout

\begin_layout Plain Layout


\backslash
caption{SVMs from scikit-learn and Twister with rgb as features } 
\end_layout

\begin_layout Plain Layout


\backslash
label{svm_table} 
\end_layout

\begin_layout Plain Layout


\backslash
end{figure}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{figure}
\end_layout

\begin_layout Plain Layout


\backslash
begin{tabular}{|l|r|r|r|} 	
\end_layout

\begin_layout Plain Layout


\backslash
hline 
\end_layout

\begin_layout Plain Layout

Classifier & Accuracy & training time in s & test time in s 
\backslash

\backslash
  	
\end_layout

\begin_layout Plain Layout


\backslash
hline 
\end_layout

\begin_layout Plain Layout

GaussianNB & 0.9475908597 	& 0.042224 & 0.075098 
\backslash

\backslash
  	
\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout

KNN & 0.9677196684 & 1.57 & 5.29
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout

Decision Tree & 0.9569552165 	& 0.563767 	& 0.057934 	
\backslash

\backslash
  	
\end_layout

\begin_layout Plain Layout


\backslash
hline 
\end_layout

\begin_layout Plain Layout

RandomForest  & 0.9637635858 	& 1.698716 	& 0.399092 
\backslash

\backslash
  	
\end_layout

\begin_layout Plain Layout


\backslash
hline  
\end_layout

\begin_layout Plain Layout


\backslash
end{tabular}  
\end_layout

\begin_layout Plain Layout


\backslash
caption{Different classifiers used with rgb features.} 
\end_layout

\begin_layout Plain Layout


\backslash
label{different_classifiers_table} 
\end_layout

\begin_layout Plain Layout


\backslash
end{figure}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
More information on SVMs in general can be found at 
\begin_inset CommandInset citation
LatexCommand cite
key "Han2011"

\end_inset

.
\end_layout

\begin_layout Standard
Because support vector machines maximize the margin between the decision
 boundary and the support vectors, they do not overfit as easily as other
 classifiers like decision trees for example.
 However, solving the quadratic problem can have a complexity between 
\begin_inset Formula $O(n^{2})$
\end_inset

 and 
\begin_inset Formula $O(n^{3})$
\end_inset

 depending on the used algorithm and implementation.
 As figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "svm_table"

\end_inset

 shows training an svm takes much more time to be trained than other classifiers.
 This is especially true if a non linear kernel is used, e.g.
 rbf kernel.
 A linear svm is much faster but this goes along with a drop in accuracy.
 To get both a feasible training time and a good accuracy, a kernel approximatio
n is used together with a linear SVM.
 A kernel approximation is used before training a SVM.
 It adds additional features to the data.
 The features added 
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{figure} 
\end_layout

\begin_layout Plain Layout


\backslash
centering 
\end_layout

\begin_layout Plain Layout


\backslash
includegraphics[width=0.8
\backslash
linewidth]{graphics/sklearn_runtime} 
\end_layout

\begin_layout Plain Layout


\backslash
caption{SVC training time with increasing sample} 
\end_layout

\begin_layout Plain Layout


\backslash
label{fig:sklearn_runtime} 
\end_layout

\begin_layout Plain Layout


\backslash
end{figure}
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Other Classifiers
\end_layout

\begin_layout Standard
There are some other classifiers besides support vector machines.
 While the focus is on SVMs and they were optimized the most, some models
 with other classifiers were tested too.
 Naive Bayes is one of them.
 Due to its simplicity it is quite fast.
 Unfortunatly the accuracy score is not good since Naive Bayes assumes independe
ncy of features which is obiously not the cause for RGB values of an image.
 
\end_layout

\begin_layout Standard
While KNearestNeighbour considers feature dependencies and therefore has
 a higher accuracy, it's training time is also higher than the one of naive
 bayes.
 Apart from that figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "different_classifiers_table"

\end_inset

 shows that the prediction takes much longer since the distances to all
 instances have to be calculated.
\end_layout

\begin_layout Standard
Decision trees have a better accuracy than naive bayes as well but not as
 good as KNN.
 While their training time is larger than the one of naive bayes, it is
 way faster than KNN.
 For the random forest classifier, which uses ten randomized decision trees,
 the accuracy as well as the training and testing time increase.
 
\end_layout

\begin_layout Subsection
Data Post Processing
\end_layout

\begin_layout Standard
After the model is created an image can be predicted.
 During the preprocessing the image is flattened and several features are
 added, so that every row contains one pixel.
 Since the order of the pixel is contained, the predicted labels can be
 reshaped to form a mask for the given image.
 This gives a much better impression of the performance of the model than
 the accuracy score because the data is not balanced.
 If the mask of the image is given, the predicted mask and the original
 mask can easily be compared by opening both masks or calling the 
\emph on
compare_to_mask
\emph default
 function.
 The latter calculates the accuracy, f-score and the confusion matrix.
 Furthermore it also visualizes the confusion matrix as an image.
 
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO implement function and include an image
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Conclusion
\end_layout

\begin_layout Standard

\end_layout

\end_body
\end_document
